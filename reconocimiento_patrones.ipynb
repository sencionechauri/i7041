{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Reconocimiento de Patrones</p>\n",
    "## <p style=\"text-align: center;\">Ejemplo: Clasificación de Prendas</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo utilizaremos un modelo de red neuronal para clasificar imagenes de prendas de vestir y accesorios. El ejemplo hará uso de Keras, una API de alto nivel para crear y entrenar modelos en Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos por importar los módulos necesarios e imprimir la versión de Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Numpy y matplotlib para graficar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación importaremos el conjunto de datos (dataset) con el cual trabajaremos. Para este ejemplo usaremos el dataset de Fashion MNIST que contiene 70000 imágenes en escala de grises y 10 categorias. Cada imagen es un artículo de vestir con una resolución de 28 x 28 pixeles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60000 imágenes son utilizadas para entrenar la red neuronal y 10000 imagenes para evaluar la precisión de la red al momento de clasificar imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al cargar el dataset, tendremos cuatro arreglos de Numpy:\n",
    "\n",
    "<ul>\n",
    "<li>train_images y train_labels son los arreglos con datos de entrenamiento que el modelo utiliza para aprender.</li>\n",
    "<li>test_images y test_labels son los datos con los cuales probamos el modelo.</li>\n",
    "</ul>\n",
    "\n",
    "Las imágenes son arreglos de Numpy de tamaño 28 x 28 con valores entre 0 y 255. Las etiquetas son un arreglo de enteros entre 0 y 9 que corresponden a las siguientes clases:\n",
    "\n",
    "|Etiqueta|Clase|\n",
    "|--------|-----|\n",
    "|0|T-shirt/top|\n",
    "|1|Trouser|\n",
    "|2|Pullover|\n",
    "|3|Dress|\n",
    "|4|Coat|\n",
    "|5|Sandal|\n",
    "|6|Shirt|\n",
    "|7|Sneaker|\n",
    "|8|Bag|\n",
    "|9|Ankle boot|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen tiene asignada una etiqueta, sin embargo los nombres de las clases no están incluidos en el dataset. Podemos almacenarlos en una lista para utilizarlos después."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos deben ser preprocesados antes de entrenar la red. Si revisamos una imagen en el conjunto de entrenamiento, podemos ver que los valores de los pixeles caen en el rango entre 0 y 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[111])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de alimentar los datos a la red neuronal, debemos escalar los valores para que caigan en el rango entre 0 y 1. Es importante escalar tanto los datos de entrenamiento como los de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los primeros 9 artículos para corroborar que estamos listos para entrenar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos contruir una red neuronal multicapa para poder lograr el reconocimiento y clasificación de las prendas. Primero configuraremos las capas y posteriormente compilaremos el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de las Capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El bloque de construcción básico de una red neuronal es una capa (y la neurona, por supuesto). Las capas extraen representaciones a partir de los datos que se les alimentan. Con suerte, estas representaciones son significativas para el problema en cuestión.\n",
    "\n",
    "Mucho de lo realizado con aprendizaje profundo (deep learning) consiste en secuenciar capas simples una tras otra. La mayoría de las capas, tales como tf.keras.layers.Dense, tienen parámetros que son aprendidos durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)), # Convertimos las imagenes en arreglos lineales de tamaño 28x28 \n",
    "                             tf.keras.layers.Dense(128, activation='relu'), # Capa con 128 neuronas conectadas densamente\n",
    "                             tf.keras.layers.Dense(10)]) # Capa con una neurona por cada clase del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes que el modelo esté listo para el entrenamiento, necesita unas configuraciones más, las cuales son agregadas durante el proceso de compilación:\n",
    "\n",
    "<ul>\n",
    "<li>Optimizador: Es la forma en que el modelo es actualizado basado en los datos que ve y la función de pérdida.</li>\n",
    "<li>Función de pérdida: Mide qué tan preciso es el modelo durante el entrenamiento. Queremos minimizar esta función para guiar al modelo en la dirección correcta.</li>\n",
    "<li>Métricas: Utilizadas para monitorear los pasos de entrenamiento y prueba.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el modelo de red neuronal requiere los siguientes pasos:\n",
    "\n",
    "<ol>\n",
    "<li>Alimentar los datos de entrenamiento al modelo.</li>\n",
    "<li>El modelo aprende a asociar imagenes y etiquetas.</li>\n",
    "<li>Preguntar al modelo por predicciones sobre el conjunto de prueba.</li>\n",
    "<li>Verificar que las predicciones correspondan con las etiquetas de prueba. </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alimentar al Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar el entrenamiento, llamamos el método model.fit del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras el entramiento avanza, las métricas de precisión y pérdida se depliegan. El modelo alcanza una precisión de alrededor del 90% en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluar la Precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, comparamos cómo se comporta el modelo con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nPrecisión en datos de prueba:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta que la precisión en el dataset de prueba es un poco menor que en los datos de entrenamiento. Esta diferencia entre la precisión de entrenamiento y prueba representa un sobre-entrenamiento. El sobre-entrenamiento sucede cuando un modelo de machine learning se desempeña peor en datos nuevos no antes vistos que en los de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizar Predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo entrenado, ahora podemos hacer predicciones sobre las imágenes. Agregaremos una capa softmax para convertir las salidas lineales del modelo en probabilidades, que serán más fáciles de interpretar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, el modelo ha predicho la etiqueta para cada imagen en el set de prueba. Podemos ver la predicción de la primer imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una predicción es un arreglo de 10 números. Cada número representa la confianza del modelo de que la imagen corresponda a cada una de las 10 categorias. Podemos ver cual etiqueta tiene el valor de confianza más alto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo tiene al rededor del 97% de confianza que la imagen corresponde a la categoria 9. Si examinamos la etiqueta correspondiente en el conjunto de pruebas, observamos que la clasificación es correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momento de practicar. Intenta desplegar la imgaen correspondiente al primer artículo en el conjunto de prueba, junto con el nombre del artículo y verifica si la categoría coincide con el artículo predicho por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSPIA2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
